{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbcc4330-6bb6-4942-a617-dc6e14313d8a",
   "metadata": {},
   "source": [
    "## Transfer learning using MobileNetV3\n",
    "\n",
    "Training neural networks on images is time-consuming if starting from a scratch. Transfer learning is a powerful technique as it lets use the networks and the trained parameters of previous models. With slight modification you can take advantage of other models for your purpose with minimum efforts.\n",
    "\n",
    "This Notebook will show how to do that. We will be using MobileNetV3 model that provides good classification performance with reasonable calculation requirements for inference. We will be using the pretrained model parameters, but our task has only have 10 objects to classify using the Fashion-MNIST dataset, where MobileNetV3 can classify 1000 items. To be able to use MobileNetV3 for our task, We only need to modify the final layer and train its parameters without updating the other parameters. This will make our training process much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a446fc76-77d9-486f-8590-4db4fb50302d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch Version:  2.5.1\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Tue_Feb_27_16:28:36_Pacific_Standard_Time_2024\n",
      "Cuda compilation tools, release 12.4, V12.4.99\n",
      "Build cuda_12.4.r12.4/compiler.33961263_0\n"
     ]
    }
   ],
   "source": [
    "# Import crucial pytorch packages\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "print(\"Pytorch Version: \", torch.__version__)\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e24782d-9024-413e-888e-7bdf5454ff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Fashion-MNIST dataset which is available in the Pytorch torchvision package.\n",
    "def load_data(batch_size, data_dir=\"data\"):\n",
    "    # Normalize the input data \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ]) \n",
    "\n",
    "    # Download the dataset and create trainloader and testloader\n",
    "    trainset = datasets.FashionMNIST(data_dir, download=True, train=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "    testset = datasets.FashionMNIST(data_dir, download=True, train=False, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size)\n",
    "\n",
    "    return trainloader, testloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7c06141-656e-4fa5-b646-b357f30af66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset using load_data method. We will use the batch size of 64.\n",
    "trainloader, testloader = load_data(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e0b09c0-c356-4faf-81c8-2f25f6efb406",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Return the list of classes in the Fashion-MNIST dataset.\n",
    "def get_class_names():\n",
    "    return [\n",
    "        \"T-shirt/top\",\n",
    "        \"Trouser\",\n",
    "        \"Pullover\",\n",
    "        \"Dress\",\n",
    "        \"Coat\",\n",
    "        \"Sandal\",\n",
    "        \"Shirt\",\n",
    "        \"Sneaker\",\n",
    "        \"Bag\",\n",
    "        \"Ankle boot\",\n",
    "    ]\n",
    "\n",
    "# Return the class name for the given index.\n",
    "def get_class_name(class_index):\n",
    "    return get_class_names()[class_index]\n",
    "\n",
    "# Return the class index for the given name.\n",
    "def get_class_index(class_name):\n",
    "    return get_class_names().index(class_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9835867d-06bc-4904-a08b-9b7958f10da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_index=0, class_name=T-shirt/top\n",
      "class_index=1, class_name=Trouser\n",
      "class_index=2, class_name=Pullover\n",
      "class_index=3, class_name=Dress\n",
      "class_index=4, class_name=Coat\n",
      "class_index=5, class_name=Sandal\n",
      "class_index=6, class_name=Shirt\n",
      "class_index=7, class_name=Sneaker\n",
      "class_index=8, class_name=Bag\n",
      "class_index=9, class_name=Ankle boot\n",
      "class_label=T-shirt/top, class_index=0\n",
      "class_label=Trouser, class_index=1\n",
      "class_label=Pullover, class_index=2\n",
      "class_label=Dress, class_index=3\n",
      "class_label=Coat, class_index=4\n",
      "class_label=Sandal, class_index=5\n",
      "class_label=Shirt, class_index=6\n",
      "class_label=Sneaker, class_index=7\n",
      "class_label=Bag, class_index=8\n",
      "class_label=Ankle boot, class_index=9\n"
     ]
    }
   ],
   "source": [
    "# Test above methods\n",
    "for class_index in range(10):\n",
    "    print(f\"class_index={class_index}, class_name={get_class_name(class_index)}\")\n",
    "\n",
    "for class_label in get_class_names():\n",
    "    print(f\"class_label={class_label}, class_index={get_class_index(class_label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c15551c-1da7-4acf-acee-1dc83e13fc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of image = torch.Size([64, 1, 28, 28]), Shape of labels = torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show 10 images in the Fashion-MNIST dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "\n",
    "# Obtain the first batch just to visualize\n",
    "images, labels = next(iter(trainloader))\n",
    "print(f\"Shape of image = {images.shape}, Shape of labels = {labels.shape}\")\n",
    "\n",
    "fig = plt.figure(figsize=(15,4))\n",
    "plot_size = 10\n",
    "\n",
    "for idx in np.arange(plot_size):\n",
    "    ax = fig.add_subplot(2, plot_size//2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(get_class_name(int(labels[idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e7f1d0b-eb0c-436e-9d6a-bbc38d179729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Hardswish()\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
      "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
      "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): Conv2dNormActivation(\n",
      "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Hardswish()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
      "    (1): Hardswish()\n",
      "    (2): Dropout(p=0.2, inplace=True)\n",
      "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create a MobileNetV3 model instance\n",
    "import torchvision.models as models\n",
    "mobilenet_v3_model = models.mobilenet_v3_small(predtrained=True)\n",
    "print(mobilenet_v3_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3ddc3c1-2b97-4a5c-bc5f-27b20943dfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=576, out_features=1024, bias=True)\n",
      "  (1): Hardswish()\n",
      "  (2): Dropout(p=0.2, inplace=True)\n",
      "  (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Look at the final layer of the original MobileNetV3 that would classify 1000 objects. \n",
    "# We need to replace this layer with a fully connected network that would classify only 10 objects.\n",
    "print(mobilenet_v3_model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "146dd2b5-642f-4d08-a210-0c71d7f036d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class ModifiedMobileNetV3(nn.Module):\n",
    "    # Initialize model structure\n",
    "    def __init__(self):\n",
    "        super(ModifiedMobileNetV3, self).__init__()\n",
    "        self.model = models.mobilenet_v3_small(pretrained=True)\n",
    "\n",
    "        # Replace the final layer to 1024x10 fully connected layer\n",
    "        self.model.classifier[3] = nn.Linear(1024, 10)\n",
    "        self.freeze()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.repeat(1, 3, 1, 1)\n",
    "        # Format the input image to 224x224 as this is the image size that MobileNetV3 would use\n",
    "        if x.shape[2:] != (224, 224):\n",
    "            x = F.interpolate(x, size=(224, 224), mode=\"bilinear\", align_corners=False)\n",
    "        return self.model(x)\n",
    "\n",
    "    def freeze(self):\n",
    "        # Block parameter updates on all layers\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        # Unblock parameter updates only for the final layer\n",
    "        for param in self.model.classifier[3].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    # Allow model parameter updates on ALL layers\n",
    "    def unfreeze(self):\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47a271c6-56af-4cb8-b374-2fc8f4e9de35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModifiedMobileNetV3(\n",
      "  (model): MobileNetV3(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): Hardswish()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
      "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
      "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
      "            (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
      "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
      "            (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
      "            (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (2): Hardswish()\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=576, out_features=1024, bias=True)\n",
      "      (1): Hardswish()\n",
      "      (2): Dropout(p=0.2, inplace=True)\n",
      "      (3): Linear(in_features=1024, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jkang\\.conda\\envs\\udacity\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jkang\\.conda\\envs\\udacity\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Create a modified model instance\n",
    "model = ModifiedMobileNetV3()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "551ec4f5-d29b-4d03-82e6-c5afe5f31d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab64e4c5-7e02-4b35-9670-bd536d85d3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set the CUDA device for the model\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d269aa7-5a85-46a1-90b1-b989679b2536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50], Batch [0/938], Loss:2.32989\n",
      "Epoch [0/50], Batch [100/938], Loss:1.88842\n",
      "Epoch [0/50], Batch [200/938], Loss:1.55098\n",
      "Epoch [0/50], Batch [300/938], Loss:1.35767\n",
      "Epoch [0/50], Batch [400/938], Loss:1.29191\n",
      "Epoch [0/50], Batch [500/938], Loss:1.20502\n",
      "Epoch [0/50], Batch [600/938], Loss:1.04438\n",
      "Epoch [0/50], Batch [700/938], Loss:0.92111\n",
      "Epoch [0/50], Batch [800/938], Loss:1.01610\n",
      "Epoch [0/50], Batch [900/938], Loss:0.88573\n",
      "Epoch [1/50], Batch [0/938], Loss:0.96205\n",
      "Epoch [1/50], Batch [100/938], Loss:0.91589\n",
      "Epoch [1/50], Batch [200/938], Loss:0.77741\n",
      "Epoch [1/50], Batch [300/938], Loss:0.83112\n",
      "Epoch [1/50], Batch [400/938], Loss:0.83759\n",
      "Epoch [1/50], Batch [500/938], Loss:0.68382\n",
      "Epoch [1/50], Batch [600/938], Loss:0.69465\n",
      "Epoch [1/50], Batch [700/938], Loss:0.71767\n",
      "Epoch [1/50], Batch [800/938], Loss:0.73554\n",
      "Epoch [1/50], Batch [900/938], Loss:0.76865\n",
      "Epoch [2/50], Batch [0/938], Loss:0.72091\n",
      "Epoch [2/50], Batch [100/938], Loss:0.69431\n",
      "Epoch [2/50], Batch [200/938], Loss:0.67704\n",
      "Epoch [2/50], Batch [300/938], Loss:0.79771\n",
      "Epoch [2/50], Batch [400/938], Loss:0.66423\n",
      "Epoch [2/50], Batch [500/938], Loss:0.50318\n",
      "Epoch [2/50], Batch [600/938], Loss:0.53995\n",
      "Epoch [2/50], Batch [700/938], Loss:0.71119\n",
      "Epoch [2/50], Batch [800/938], Loss:0.68434\n",
      "Epoch [2/50], Batch [900/938], Loss:0.58867\n",
      "Epoch [3/50], Batch [0/938], Loss:0.74633\n",
      "Epoch [3/50], Batch [100/938], Loss:0.52579\n",
      "Epoch [3/50], Batch [200/938], Loss:0.64018\n",
      "Epoch [3/50], Batch [300/938], Loss:0.63805\n",
      "Epoch [3/50], Batch [400/938], Loss:0.75260\n",
      "Epoch [3/50], Batch [500/938], Loss:0.62693\n",
      "Epoch [3/50], Batch [600/938], Loss:0.53878\n",
      "Epoch [3/50], Batch [700/938], Loss:0.67248\n",
      "Epoch [3/50], Batch [800/938], Loss:0.64325\n",
      "Epoch [3/50], Batch [900/938], Loss:0.61213\n",
      "Epoch [4/50], Batch [0/938], Loss:0.60251\n",
      "Epoch [4/50], Batch [100/938], Loss:0.54338\n",
      "Epoch [4/50], Batch [200/938], Loss:0.41892\n",
      "Epoch [4/50], Batch [300/938], Loss:0.51914\n",
      "Epoch [4/50], Batch [400/938], Loss:0.35583\n",
      "Epoch [4/50], Batch [500/938], Loss:0.38303\n",
      "Epoch [4/50], Batch [600/938], Loss:0.56492\n",
      "Epoch [4/50], Batch [700/938], Loss:0.52835\n",
      "Epoch [4/50], Batch [800/938], Loss:0.46763\n",
      "Epoch [4/50], Batch [900/938], Loss:0.56694\n",
      "Epoch [5/50], Batch [0/938], Loss:0.46343\n",
      "Epoch [5/50], Batch [100/938], Loss:0.60947\n",
      "Epoch [5/50], Batch [200/938], Loss:0.45479\n",
      "Epoch [5/50], Batch [300/938], Loss:0.50345\n",
      "Epoch [5/50], Batch [400/938], Loss:0.51041\n",
      "Epoch [5/50], Batch [500/938], Loss:0.58557\n",
      "Epoch [5/50], Batch [600/938], Loss:0.60534\n",
      "Epoch [5/50], Batch [700/938], Loss:0.56079\n",
      "Epoch [5/50], Batch [800/938], Loss:0.48349\n",
      "Epoch [5/50], Batch [900/938], Loss:0.59139\n",
      "Epoch [6/50], Batch [0/938], Loss:0.48822\n",
      "Epoch [6/50], Batch [100/938], Loss:0.48472\n",
      "Epoch [6/50], Batch [200/938], Loss:0.61714\n",
      "Epoch [6/50], Batch [300/938], Loss:0.52211\n",
      "Epoch [6/50], Batch [400/938], Loss:0.45574\n",
      "Epoch [6/50], Batch [500/938], Loss:0.58206\n",
      "Epoch [6/50], Batch [600/938], Loss:0.52267\n",
      "Epoch [6/50], Batch [700/938], Loss:0.51862\n",
      "Epoch [6/50], Batch [800/938], Loss:0.48268\n",
      "Epoch [6/50], Batch [900/938], Loss:0.46376\n",
      "Epoch [7/50], Batch [0/938], Loss:0.46631\n",
      "Epoch [7/50], Batch [100/938], Loss:0.44749\n",
      "Epoch [7/50], Batch [200/938], Loss:0.53626\n",
      "Epoch [7/50], Batch [300/938], Loss:0.49607\n",
      "Epoch [7/50], Batch [400/938], Loss:0.46200\n",
      "Epoch [7/50], Batch [500/938], Loss:0.51016\n",
      "Epoch [7/50], Batch [600/938], Loss:0.59700\n",
      "Epoch [7/50], Batch [700/938], Loss:0.48952\n",
      "Epoch [7/50], Batch [800/938], Loss:0.48490\n",
      "Epoch [7/50], Batch [900/938], Loss:0.57068\n",
      "Epoch [8/50], Batch [0/938], Loss:0.62073\n",
      "Epoch [8/50], Batch [100/938], Loss:0.36922\n",
      "Epoch [8/50], Batch [200/938], Loss:0.59909\n",
      "Epoch [8/50], Batch [300/938], Loss:0.35437\n",
      "Epoch [8/50], Batch [400/938], Loss:0.63011\n",
      "Epoch [8/50], Batch [500/938], Loss:0.49909\n",
      "Epoch [8/50], Batch [600/938], Loss:0.40701\n",
      "Epoch [8/50], Batch [700/938], Loss:0.49721\n",
      "Epoch [8/50], Batch [800/938], Loss:0.49734\n",
      "Epoch [8/50], Batch [900/938], Loss:0.40517\n",
      "Epoch [9/50], Batch [0/938], Loss:0.51174\n",
      "Epoch [9/50], Batch [100/938], Loss:0.57821\n",
      "Epoch [9/50], Batch [200/938], Loss:0.51278\n",
      "Epoch [9/50], Batch [300/938], Loss:0.47857\n",
      "Epoch [9/50], Batch [400/938], Loss:0.46979\n",
      "Epoch [9/50], Batch [500/938], Loss:0.45856\n",
      "Epoch [9/50], Batch [600/938], Loss:0.39171\n",
      "Epoch [9/50], Batch [700/938], Loss:0.54756\n",
      "Epoch [9/50], Batch [800/938], Loss:0.49170\n",
      "Epoch [9/50], Batch [900/938], Loss:0.50262\n",
      "Epoch [10/50], Batch [0/938], Loss:0.46372\n",
      "Epoch [10/50], Batch [100/938], Loss:0.56273\n",
      "Epoch [10/50], Batch [200/938], Loss:0.47573\n",
      "Epoch [10/50], Batch [300/938], Loss:0.47414\n",
      "Epoch [10/50], Batch [400/938], Loss:0.40986\n",
      "Epoch [10/50], Batch [500/938], Loss:0.34610\n",
      "Epoch [10/50], Batch [600/938], Loss:0.41797\n",
      "Epoch [10/50], Batch [700/938], Loss:0.63929\n",
      "Epoch [10/50], Batch [800/938], Loss:0.53638\n",
      "Epoch [10/50], Batch [900/938], Loss:0.60563\n",
      "Epoch [11/50], Batch [0/938], Loss:0.43609\n",
      "Epoch [11/50], Batch [100/938], Loss:0.41216\n",
      "Epoch [11/50], Batch [200/938], Loss:0.46125\n",
      "Epoch [11/50], Batch [300/938], Loss:0.38861\n",
      "Epoch [11/50], Batch [400/938], Loss:0.37484\n",
      "Epoch [11/50], Batch [500/938], Loss:0.39309\n",
      "Epoch [11/50], Batch [600/938], Loss:0.53558\n",
      "Epoch [11/50], Batch [700/938], Loss:0.41366\n",
      "Epoch [11/50], Batch [800/938], Loss:0.55914\n",
      "Epoch [11/50], Batch [900/938], Loss:0.66365\n",
      "Epoch [12/50], Batch [0/938], Loss:0.33464\n",
      "Epoch [12/50], Batch [100/938], Loss:0.65412\n",
      "Epoch [12/50], Batch [200/938], Loss:0.53354\n",
      "Epoch [12/50], Batch [300/938], Loss:0.45284\n",
      "Epoch [12/50], Batch [400/938], Loss:0.42176\n",
      "Epoch [12/50], Batch [500/938], Loss:0.42583\n",
      "Epoch [12/50], Batch [600/938], Loss:0.43461\n",
      "Epoch [12/50], Batch [700/938], Loss:0.43851\n",
      "Epoch [12/50], Batch [800/938], Loss:0.51847\n",
      "Epoch [12/50], Batch [900/938], Loss:0.58275\n",
      "Epoch [13/50], Batch [0/938], Loss:0.44053\n",
      "Epoch [13/50], Batch [100/938], Loss:0.58371\n",
      "Epoch [13/50], Batch [200/938], Loss:0.38658\n",
      "Epoch [13/50], Batch [300/938], Loss:0.58329\n",
      "Epoch [13/50], Batch [400/938], Loss:0.52966\n",
      "Epoch [13/50], Batch [500/938], Loss:0.36914\n",
      "Epoch [13/50], Batch [600/938], Loss:0.37370\n",
      "Epoch [13/50], Batch [700/938], Loss:0.40210\n",
      "Epoch [13/50], Batch [800/938], Loss:0.43435\n",
      "Epoch [13/50], Batch [900/938], Loss:0.39996\n",
      "Epoch [14/50], Batch [0/938], Loss:0.37695\n",
      "Epoch [14/50], Batch [100/938], Loss:0.49707\n",
      "Epoch [14/50], Batch [200/938], Loss:0.51960\n",
      "Epoch [14/50], Batch [300/938], Loss:0.56175\n",
      "Epoch [14/50], Batch [400/938], Loss:0.36338\n",
      "Epoch [14/50], Batch [500/938], Loss:0.40015\n",
      "Epoch [14/50], Batch [600/938], Loss:0.46251\n",
      "Epoch [14/50], Batch [700/938], Loss:0.32979\n",
      "Epoch [14/50], Batch [800/938], Loss:0.47762\n",
      "Epoch [14/50], Batch [900/938], Loss:0.43934\n",
      "Epoch [15/50], Batch [0/938], Loss:0.46378\n",
      "Epoch [15/50], Batch [100/938], Loss:0.46455\n",
      "Epoch [15/50], Batch [200/938], Loss:0.50589\n",
      "Epoch [15/50], Batch [300/938], Loss:0.45115\n",
      "Epoch [15/50], Batch [400/938], Loss:0.30152\n",
      "Epoch [15/50], Batch [500/938], Loss:0.48947\n",
      "Epoch [15/50], Batch [600/938], Loss:0.48642\n",
      "Epoch [15/50], Batch [700/938], Loss:0.43440\n",
      "Epoch [15/50], Batch [800/938], Loss:0.43487\n",
      "Epoch [15/50], Batch [900/938], Loss:0.48587\n",
      "Epoch [16/50], Batch [0/938], Loss:0.39315\n",
      "Epoch [16/50], Batch [100/938], Loss:0.44069\n",
      "Epoch [16/50], Batch [200/938], Loss:0.49430\n",
      "Epoch [16/50], Batch [300/938], Loss:0.54421\n",
      "Epoch [16/50], Batch [400/938], Loss:0.57338\n",
      "Epoch [16/50], Batch [500/938], Loss:0.31846\n",
      "Epoch [16/50], Batch [600/938], Loss:0.33699\n",
      "Epoch [16/50], Batch [700/938], Loss:0.33076\n",
      "Epoch [16/50], Batch [800/938], Loss:0.47612\n",
      "Epoch [16/50], Batch [900/938], Loss:0.40863\n",
      "Epoch [17/50], Batch [0/938], Loss:0.42855\n",
      "Epoch [17/50], Batch [100/938], Loss:0.37979\n",
      "Epoch [17/50], Batch [200/938], Loss:0.35916\n",
      "Epoch [17/50], Batch [300/938], Loss:0.27378\n",
      "Epoch [17/50], Batch [400/938], Loss:0.42412\n",
      "Epoch [17/50], Batch [500/938], Loss:0.32035\n",
      "Epoch [17/50], Batch [600/938], Loss:0.54740\n",
      "Epoch [17/50], Batch [700/938], Loss:0.45031\n",
      "Epoch [17/50], Batch [800/938], Loss:0.39557\n",
      "Epoch [17/50], Batch [900/938], Loss:0.29224\n",
      "Epoch [18/50], Batch [0/938], Loss:0.32623\n",
      "Epoch [18/50], Batch [100/938], Loss:0.47499\n",
      "Epoch [18/50], Batch [200/938], Loss:0.56578\n",
      "Epoch [18/50], Batch [300/938], Loss:0.33824\n",
      "Epoch [18/50], Batch [400/938], Loss:0.34530\n",
      "Epoch [18/50], Batch [500/938], Loss:0.48425\n",
      "Epoch [18/50], Batch [600/938], Loss:0.57028\n",
      "Epoch [18/50], Batch [700/938], Loss:0.35119\n",
      "Epoch [18/50], Batch [800/938], Loss:0.59468\n",
      "Epoch [18/50], Batch [900/938], Loss:0.45412\n",
      "Epoch [19/50], Batch [0/938], Loss:0.37560\n",
      "Epoch [19/50], Batch [100/938], Loss:0.32609\n",
      "Epoch [19/50], Batch [200/938], Loss:0.65256\n",
      "Epoch [19/50], Batch [300/938], Loss:0.35652\n",
      "Epoch [19/50], Batch [400/938], Loss:0.38934\n",
      "Epoch [19/50], Batch [500/938], Loss:0.50752\n",
      "Epoch [19/50], Batch [600/938], Loss:0.36759\n",
      "Epoch [19/50], Batch [700/938], Loss:0.38151\n",
      "Epoch [19/50], Batch [800/938], Loss:0.54736\n",
      "Epoch [19/50], Batch [900/938], Loss:0.50832\n",
      "Epoch [20/50], Batch [0/938], Loss:0.54173\n",
      "Epoch [20/50], Batch [100/938], Loss:0.50040\n",
      "Epoch [20/50], Batch [200/938], Loss:0.44316\n",
      "Epoch [20/50], Batch [300/938], Loss:0.32777\n",
      "Epoch [20/50], Batch [400/938], Loss:0.47378\n",
      "Epoch [20/50], Batch [500/938], Loss:0.50755\n",
      "Epoch [20/50], Batch [600/938], Loss:0.50816\n",
      "Epoch [20/50], Batch [700/938], Loss:0.35663\n",
      "Epoch [20/50], Batch [800/938], Loss:0.37365\n",
      "Epoch [20/50], Batch [900/938], Loss:0.38482\n",
      "Epoch [21/50], Batch [0/938], Loss:0.38215\n",
      "Epoch [21/50], Batch [100/938], Loss:0.47641\n",
      "Epoch [21/50], Batch [200/938], Loss:0.50121\n",
      "Epoch [21/50], Batch [300/938], Loss:0.57840\n",
      "Epoch [21/50], Batch [400/938], Loss:0.44843\n",
      "Epoch [21/50], Batch [500/938], Loss:0.41155\n",
      "Epoch [21/50], Batch [600/938], Loss:0.44224\n",
      "Epoch [21/50], Batch [700/938], Loss:0.39976\n",
      "Epoch [21/50], Batch [800/938], Loss:0.36544\n",
      "Epoch [21/50], Batch [900/938], Loss:0.38694\n",
      "Epoch [22/50], Batch [0/938], Loss:0.28233\n",
      "Epoch [22/50], Batch [100/938], Loss:0.41357\n",
      "Epoch [22/50], Batch [200/938], Loss:0.45670\n",
      "Epoch [22/50], Batch [300/938], Loss:0.53176\n",
      "Epoch [22/50], Batch [400/938], Loss:0.37495\n",
      "Epoch [22/50], Batch [500/938], Loss:0.35262\n",
      "Epoch [22/50], Batch [600/938], Loss:0.39302\n",
      "Epoch [22/50], Batch [700/938], Loss:0.40594\n",
      "Epoch [22/50], Batch [800/938], Loss:0.38091\n",
      "Epoch [22/50], Batch [900/938], Loss:0.56944\n",
      "Epoch [23/50], Batch [0/938], Loss:0.43099\n",
      "Epoch [23/50], Batch [100/938], Loss:0.43840\n",
      "Epoch [23/50], Batch [200/938], Loss:0.47812\n",
      "Epoch [23/50], Batch [300/938], Loss:0.47844\n",
      "Epoch [23/50], Batch [400/938], Loss:0.58676\n",
      "Epoch [23/50], Batch [500/938], Loss:0.34896\n",
      "Epoch [23/50], Batch [600/938], Loss:0.39571\n",
      "Epoch [23/50], Batch [700/938], Loss:0.46880\n",
      "Epoch [23/50], Batch [800/938], Loss:0.43727\n",
      "Epoch [23/50], Batch [900/938], Loss:0.54368\n",
      "Epoch [24/50], Batch [0/938], Loss:0.25300\n",
      "Epoch [24/50], Batch [100/938], Loss:0.28386\n",
      "Epoch [24/50], Batch [200/938], Loss:0.51908\n",
      "Epoch [24/50], Batch [300/938], Loss:0.26868\n",
      "Epoch [24/50], Batch [400/938], Loss:0.55793\n",
      "Epoch [24/50], Batch [500/938], Loss:0.45366\n",
      "Epoch [24/50], Batch [600/938], Loss:0.45170\n",
      "Epoch [24/50], Batch [700/938], Loss:0.26131\n",
      "Epoch [24/50], Batch [800/938], Loss:0.35884\n",
      "Epoch [24/50], Batch [900/938], Loss:0.49953\n",
      "Epoch [25/50], Batch [0/938], Loss:0.38293\n",
      "Epoch [25/50], Batch [100/938], Loss:0.66590\n",
      "Epoch [25/50], Batch [200/938], Loss:0.33972\n",
      "Epoch [25/50], Batch [300/938], Loss:0.28612\n",
      "Epoch [25/50], Batch [400/938], Loss:0.39408\n",
      "Epoch [25/50], Batch [500/938], Loss:0.29101\n",
      "Epoch [25/50], Batch [600/938], Loss:0.38698\n",
      "Epoch [25/50], Batch [700/938], Loss:0.50618\n",
      "Epoch [25/50], Batch [800/938], Loss:0.47773\n",
      "Epoch [25/50], Batch [900/938], Loss:0.41172\n",
      "Epoch [26/50], Batch [0/938], Loss:0.45072\n",
      "Epoch [26/50], Batch [100/938], Loss:0.35400\n",
      "Epoch [26/50], Batch [200/938], Loss:0.44239\n",
      "Epoch [26/50], Batch [300/938], Loss:0.36504\n",
      "Epoch [26/50], Batch [400/938], Loss:0.59225\n",
      "Epoch [26/50], Batch [500/938], Loss:0.42291\n",
      "Epoch [26/50], Batch [600/938], Loss:0.58268\n",
      "Epoch [26/50], Batch [700/938], Loss:0.28747\n",
      "Epoch [26/50], Batch [800/938], Loss:0.40723\n",
      "Epoch [26/50], Batch [900/938], Loss:0.27945\n",
      "Epoch [27/50], Batch [0/938], Loss:0.26420\n",
      "Epoch [27/50], Batch [100/938], Loss:0.44779\n",
      "Epoch [27/50], Batch [200/938], Loss:0.31262\n",
      "Epoch [27/50], Batch [300/938], Loss:0.41993\n",
      "Epoch [27/50], Batch [400/938], Loss:0.33785\n",
      "Epoch [27/50], Batch [500/938], Loss:0.45770\n",
      "Epoch [27/50], Batch [600/938], Loss:0.33227\n",
      "Epoch [27/50], Batch [700/938], Loss:0.38429\n",
      "Epoch [27/50], Batch [800/938], Loss:0.39662\n",
      "Epoch [27/50], Batch [900/938], Loss:0.48973\n",
      "Epoch [28/50], Batch [0/938], Loss:0.48362\n",
      "Epoch [28/50], Batch [100/938], Loss:0.52340\n",
      "Epoch [28/50], Batch [200/938], Loss:0.49803\n",
      "Epoch [28/50], Batch [300/938], Loss:0.39924\n",
      "Epoch [28/50], Batch [400/938], Loss:0.38805\n",
      "Epoch [28/50], Batch [500/938], Loss:0.45724\n",
      "Epoch [28/50], Batch [600/938], Loss:0.44981\n",
      "Epoch [28/50], Batch [700/938], Loss:0.47288\n",
      "Epoch [28/50], Batch [800/938], Loss:0.26115\n",
      "Epoch [28/50], Batch [900/938], Loss:0.37093\n",
      "Epoch [29/50], Batch [0/938], Loss:0.54047\n",
      "Epoch [29/50], Batch [100/938], Loss:0.35750\n",
      "Epoch [29/50], Batch [200/938], Loss:0.26889\n",
      "Epoch [29/50], Batch [300/938], Loss:0.43393\n",
      "Epoch [29/50], Batch [400/938], Loss:0.46149\n",
      "Epoch [29/50], Batch [500/938], Loss:0.32537\n",
      "Epoch [29/50], Batch [600/938], Loss:0.53182\n",
      "Epoch [29/50], Batch [700/938], Loss:0.36693\n",
      "Epoch [29/50], Batch [800/938], Loss:0.44894\n",
      "Epoch [29/50], Batch [900/938], Loss:0.44244\n",
      "Epoch [30/50], Batch [0/938], Loss:0.30557\n",
      "Epoch [30/50], Batch [100/938], Loss:0.23237\n",
      "Epoch [30/50], Batch [200/938], Loss:0.24232\n",
      "Epoch [30/50], Batch [300/938], Loss:0.37789\n",
      "Epoch [30/50], Batch [400/938], Loss:0.25406\n",
      "Epoch [30/50], Batch [500/938], Loss:0.29713\n",
      "Epoch [30/50], Batch [600/938], Loss:0.48547\n",
      "Epoch [30/50], Batch [700/938], Loss:0.46007\n",
      "Epoch [30/50], Batch [800/938], Loss:0.34686\n",
      "Epoch [30/50], Batch [900/938], Loss:0.48951\n",
      "Epoch [31/50], Batch [0/938], Loss:0.28539\n",
      "Epoch [31/50], Batch [100/938], Loss:0.37234\n",
      "Epoch [31/50], Batch [200/938], Loss:0.37758\n",
      "Epoch [31/50], Batch [300/938], Loss:0.30626\n",
      "Epoch [31/50], Batch [400/938], Loss:0.39971\n",
      "Epoch [31/50], Batch [500/938], Loss:0.67775\n",
      "Epoch [31/50], Batch [600/938], Loss:0.43013\n",
      "Epoch [31/50], Batch [700/938], Loss:0.51848\n",
      "Epoch [31/50], Batch [800/938], Loss:0.58532\n",
      "Epoch [31/50], Batch [900/938], Loss:0.29544\n",
      "Epoch [32/50], Batch [0/938], Loss:0.38076\n",
      "Epoch [32/50], Batch [100/938], Loss:0.43436\n",
      "Epoch [32/50], Batch [200/938], Loss:0.37276\n",
      "Epoch [32/50], Batch [300/938], Loss:0.32298\n",
      "Epoch [32/50], Batch [400/938], Loss:0.41338\n",
      "Epoch [32/50], Batch [500/938], Loss:0.29217\n",
      "Epoch [32/50], Batch [600/938], Loss:0.23733\n",
      "Epoch [32/50], Batch [700/938], Loss:0.53495\n",
      "Epoch [32/50], Batch [800/938], Loss:0.43581\n",
      "Epoch [32/50], Batch [900/938], Loss:0.47960\n",
      "Epoch [33/50], Batch [0/938], Loss:0.35160\n",
      "Epoch [33/50], Batch [100/938], Loss:0.30243\n",
      "Epoch [33/50], Batch [200/938], Loss:0.44950\n",
      "Epoch [33/50], Batch [300/938], Loss:0.48358\n",
      "Epoch [33/50], Batch [400/938], Loss:0.59937\n",
      "Epoch [33/50], Batch [500/938], Loss:0.32628\n",
      "Epoch [33/50], Batch [600/938], Loss:0.29420\n",
      "Epoch [33/50], Batch [700/938], Loss:0.43613\n",
      "Epoch [33/50], Batch [800/938], Loss:0.45766\n",
      "Epoch [33/50], Batch [900/938], Loss:0.62547\n",
      "Epoch [34/50], Batch [0/938], Loss:0.41842\n",
      "Epoch [34/50], Batch [100/938], Loss:0.41932\n",
      "Epoch [34/50], Batch [200/938], Loss:0.36145\n",
      "Epoch [34/50], Batch [300/938], Loss:0.32888\n",
      "Epoch [34/50], Batch [400/938], Loss:0.51212\n",
      "Epoch [34/50], Batch [500/938], Loss:0.34236\n",
      "Epoch [34/50], Batch [600/938], Loss:0.36554\n",
      "Epoch [34/50], Batch [700/938], Loss:0.36352\n",
      "Epoch [34/50], Batch [800/938], Loss:0.44783\n",
      "Epoch [34/50], Batch [900/938], Loss:0.31539\n",
      "Epoch [35/50], Batch [0/938], Loss:0.51345\n",
      "Epoch [35/50], Batch [100/938], Loss:0.36335\n",
      "Epoch [35/50], Batch [200/938], Loss:0.34328\n",
      "Epoch [35/50], Batch [300/938], Loss:0.44029\n",
      "Epoch [35/50], Batch [400/938], Loss:0.39325\n",
      "Epoch [35/50], Batch [500/938], Loss:0.28371\n",
      "Epoch [35/50], Batch [600/938], Loss:0.57833\n",
      "Epoch [35/50], Batch [700/938], Loss:0.32063\n",
      "Epoch [35/50], Batch [800/938], Loss:0.35356\n",
      "Epoch [35/50], Batch [900/938], Loss:0.34546\n",
      "Epoch [36/50], Batch [0/938], Loss:0.26025\n",
      "Epoch [36/50], Batch [100/938], Loss:0.55666\n",
      "Epoch [36/50], Batch [200/938], Loss:0.36649\n",
      "Epoch [36/50], Batch [300/938], Loss:0.33755\n",
      "Epoch [36/50], Batch [400/938], Loss:0.49345\n",
      "Epoch [36/50], Batch [500/938], Loss:0.53246\n",
      "Epoch [36/50], Batch [600/938], Loss:0.31416\n",
      "Epoch [36/50], Batch [700/938], Loss:0.47287\n",
      "Epoch [36/50], Batch [800/938], Loss:0.53717\n",
      "Epoch [36/50], Batch [900/938], Loss:0.44949\n",
      "Epoch [37/50], Batch [0/938], Loss:0.38610\n",
      "Epoch [37/50], Batch [100/938], Loss:0.48848\n",
      "Epoch [37/50], Batch [200/938], Loss:0.43068\n",
      "Epoch [37/50], Batch [300/938], Loss:0.33941\n",
      "Epoch [37/50], Batch [400/938], Loss:0.42275\n",
      "Epoch [37/50], Batch [500/938], Loss:0.58359\n",
      "Epoch [37/50], Batch [600/938], Loss:0.21854\n",
      "Epoch [37/50], Batch [700/938], Loss:0.39121\n",
      "Epoch [37/50], Batch [800/938], Loss:0.35359\n",
      "Epoch [37/50], Batch [900/938], Loss:0.31356\n",
      "Epoch [38/50], Batch [0/938], Loss:0.29600\n",
      "Epoch [38/50], Batch [100/938], Loss:0.45304\n",
      "Epoch [38/50], Batch [200/938], Loss:0.37220\n",
      "Epoch [38/50], Batch [300/938], Loss:0.35524\n",
      "Epoch [38/50], Batch [400/938], Loss:0.46965\n",
      "Epoch [38/50], Batch [500/938], Loss:0.34967\n",
      "Epoch [38/50], Batch [600/938], Loss:0.36434\n",
      "Epoch [38/50], Batch [700/938], Loss:0.33846\n",
      "Epoch [38/50], Batch [800/938], Loss:0.41675\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    for batch_num, (images, labels) in enumerate(trainloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Start gradient calculation fresh. We don't want any accumulation from previous gradient calculations.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Calculate a forward pass for all layer on 1 batch (= 64 images)\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_func(outputs, labels)\n",
    "\n",
    "        # Back-propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights on the final layer\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_num) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{epochs}], Batch [{batch_num}/{len(trainloader)}], Loss:{loss.item():.5f}\" )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb51712-c6b8-41c2-b5a3-2e7c05e7a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predict_count = 0\n",
    "total_predict_count = 0\n",
    "loss = 0\n",
    "\n",
    "for images, labels in testloader:\n",
    "    # Set up proper device on the test data tensors\n",
    "    images_test = images.to(device)\n",
    "    labels_test = labels.to(device)\n",
    "\n",
    "    # Calculate output for prediction on the test data\n",
    "    outputs_test = model(images_test)\n",
    "    loss += loss_func(outputs_test, labels_test)\n",
    "\n",
    "    _, predicted = torch.max(outputs_test.data, dim=1)\n",
    "\n",
    "    total_predict_count += labels.size(0)\n",
    "    correct_predict_count += (predicted == labels_test).sum()\n",
    "\n",
    "print(f\"Prediction accuracy on the test data set : {100*correct_predict_count/total_predict_count:.2f}%\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ededa29-45f7-4bcf-b784-368eb185e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot a few images and the prediction results from the final batch in the test loader\n",
    "fig =plt.figure(figsize=(20,5))\n",
    "for i in np.arange(min(10, len(images_test))):\n",
    "    ax = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images_test.cpu()[i]))\n",
    "    ax.set_title(f\"Pred:{get_class_name(predicted[i])}, (Actual:{get_class_name(labels_test[i])})\", \n",
    "                 color=(\"green\" if predicted[i] == labels[i] else \"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bcc5b1-7cdf-4b4d-b219-daad793f91e6",
   "metadata": {},
   "source": [
    "### Without Training the full network, we could achieve over 85% classification performance by adapting previously trainined model for our classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5a42e-cf50-49d1-99ff-9ee7facedac7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
